{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/digit-recognizer/test.csv\n",
      "/kaggle/input/digit-recognizer/sample_submission.csv\n",
      "/kaggle/input/digit-recognizer/train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset ,DataLoader\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 785), (28000, 784))"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n",
    "test=pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n",
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting Input and Target Variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 784), (42000,))"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=train.drop(\"label\",axis=1)\n",
    "y=np.array(train['label'])\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train -Test Split -Pytorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of trainSet 33600 , len of testSet 8400\n"
     ]
    }
   ],
   "source": [
    "torch_X_train = torch.from_numpy(x.values).type(torch.FloatTensor)/255   # Normalizing the X values\n",
    "torch_y_train = torch.from_numpy(y).type(torch.LongTensor)\n",
    "myDataset = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "valid_no  = int(0.2 * len(myDataset))\n",
    "# so divide the data into trainset and testset\n",
    "trainSet,testSet = torch.utils.data.random_split(myDataset,(len(myDataset)-valid_no,valid_no))\n",
    "print(f\"len of trainSet {len(trainSet)} , len of testSet {len(testSet)}\")\n",
    "batch_size=64\n",
    "trainloader  = DataLoader(trainSet , batch_size=batch_size ,shuffle=True) \n",
    "testloader  = DataLoader(testSet , batch_size=batch_size ,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building Network**\n",
    "Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        #self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "\n",
    "        # Dropout module with 0.2 drop probability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # Now with dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        #x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "\n",
    "        # output so no dropout here\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "\n",
    "        return x\n",
    "        \n",
    "model=Network()\n",
    "\n",
    "#Adam - adaptive learning rate optimization algorithm\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "\n",
    "criterion=nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/8..  Training Loss: 0.524..  Test Loss: 0.219..  Test Accuracy: 0.933\n",
      "Epoch: 2/8..  Training Loss: 0.228..  Test Loss: 0.160..  Test Accuracy: 0.951\n",
      "Epoch: 3/8..  Training Loss: 0.172..  Test Loss: 0.143..  Test Accuracy: 0.955\n",
      "Epoch: 4/8..  Training Loss: 0.142..  Test Loss: 0.114..  Test Accuracy: 0.967\n",
      "Epoch: 5/8..  Training Loss: 0.117..  Test Loss: 0.118..  Test Accuracy: 0.963\n",
      "Epoch: 6/8..  Training Loss: 0.104..  Test Loss: 0.112..  Test Accuracy: 0.965\n",
      "Epoch: 7/8..  Training Loss: 0.091..  Test Loss: 0.100..  Test Accuracy: 0.970\n",
      "Epoch: 8/8..  Training Loss: 0.085..  Test Loss: 0.098..  Test Accuracy: 0.970\n"
     ]
    }
   ],
   "source": [
    "epochs=8\n",
    "train_losses,test_losses=[],[]\n",
    "for e in range(epochs):\n",
    "    running_loss=0\n",
    "    for images,labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        #images=images.view(images.shape[0],-1)\n",
    "        log_ps=model(images)\n",
    "        loss=criterion(log_ps,labels) # a single value for ex 2.33\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.shape[0] ## (2.33*64 + 2.22*64 + 2.12*33) / 138 \n",
    "        \n",
    "    else:\n",
    "        test_loss=0\n",
    "        accuracy=0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images,labels in testloader:\n",
    "                log_ps=model(images)\n",
    "                test_loss+=criterion(log_ps,labels) *images.shape[0]\n",
    "                ps=torch.exp(log_ps)\n",
    "                top_p,top_class=ps.topk(1,dim=1)\n",
    "                equals=top_class==labels.view(*top_class.shape)\n",
    "                accuracy+=torch.sum(equals).item()\n",
    "        model.train()\n",
    "        train_losses.append(running_loss/len(trainloader.dataset))\n",
    "        test_losses.append(test_loss.item()/len(testloader.dataset))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader.dataset)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader.dataset)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predicted  Actual\n",
       "0           9       9\n",
       "1           8       8\n",
       "2           8       8\n",
       "3           0       0\n",
       "4           4       4\n",
       "5           6       6\n",
       "6           8       8\n",
       "7           5       8\n",
       "8           2       2\n",
       "9           6       6\n",
       "10          1       1\n",
       "11          7       7\n",
       "12          1       1\n",
       "13          8       8\n",
       "14          8       8\n",
       "15          8       8"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Predicted\":top_class.view(top_class.shape[0]),\"Actual\":labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: \n",
      "\n",
      " Network(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") \n",
      "\n",
      "The state dict keys: \n",
      "\n",
      " odict_keys(['fc1.weight', 'fc1.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias'])\n",
      "109386\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model: \\n\\n\", model, '\\n')\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())\n",
    "\n",
    "# counting the number of parameters\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        #self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "\n",
    "        # Dropout module with 0.2 drop probability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # Now with dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        #x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "\n",
    "        # output so no dropout here\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "\n",
    "        return x\n",
    "        \n",
    "model=Network()\n",
    "\n",
    "\n",
    "optimizer=optim.SGD(model.parameters(),lr=1e-2,weight_decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "\n",
    "criterion=nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/8..  Training Loss: 0.063..  Test Loss: 0.087..  Test Accuracy: 0.973\n",
      "Epoch: 2/8..  Training Loss: 0.061..  Test Loss: 0.087..  Test Accuracy: 0.974\n",
      "Epoch: 3/8..  Training Loss: 0.056..  Test Loss: 0.086..  Test Accuracy: 0.975\n",
      "Epoch: 4/8..  Training Loss: 0.056..  Test Loss: 0.082..  Test Accuracy: 0.976\n",
      "Epoch: 5/8..  Training Loss: 0.053..  Test Loss: 0.083..  Test Accuracy: 0.975\n",
      "Epoch: 6/8..  Training Loss: 0.052..  Test Loss: 0.080..  Test Accuracy: 0.976\n",
      "Epoch: 7/8..  Training Loss: 0.047..  Test Loss: 0.081..  Test Accuracy: 0.976\n",
      "Epoch: 8/8..  Training Loss: 0.046..  Test Loss: 0.085..  Test Accuracy: 0.976\n"
     ]
    }
   ],
   "source": [
    "epochs=8\n",
    "train_losses,test_losses=[],[]\n",
    "for e in range(epochs):\n",
    "    running_loss=0\n",
    "    for images,labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        #images=images.view(images.shape[0],-1)\n",
    "        log_ps=model(images)\n",
    "        loss=criterion(log_ps,labels) # a single value for ex 2.33\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.shape[0] ## (2.33*64 + 2.22*64 + 2.12*33) / 138 \n",
    "        \n",
    "    else:\n",
    "        test_loss=0\n",
    "        accuracy=0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images,labels in testloader:\n",
    "                log_ps=model(images)\n",
    "                test_loss+=criterion(log_ps,labels) *images.shape[0]\n",
    "                ps=torch.exp(log_ps)\n",
    "                top_p,top_class=ps.topk(1,dim=1)\n",
    "                equals=top_class==labels.view(*top_class.shape)\n",
    "                accuracy+=torch.sum(equals).item()\n",
    "        model.train()\n",
    "        train_losses.append(running_loss/len(trainloader.dataset))\n",
    "        test_losses.append(test_loss.item()/len(testloader.dataset))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader.dataset)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader.dataset)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: \n",
      "\n",
      " Network(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") \n",
      "\n",
      "The state dict keys: \n",
      "\n",
      " odict_keys(['fc1.weight', 'fc1.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias'])\n",
      "109386\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model: \\n\\n\", model, '\\n')\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())\n",
    "\n",
    "# counting the number of parameters\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = pd.read_csv(\"../input/digit-recognizer/test.csv\")\n",
    "test_image = test_images.loc[:,test_images.columns != \"label\"].values\n",
    "test_dataset = torch.from_numpy(test_image).type(torch.FloatTensor)/255\n",
    "print(test_dataset.shape)\n",
    "#test_dataset = torch.utils.data.TensorDataset(test_dataset)\n",
    "new_test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 100, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for images in new_test_loader:\n",
    "        output = model(images)\n",
    "        ps = torch.exp(output)\n",
    "        top_p, top_class = ps.topk(1, dim = 1)\n",
    "        results += top_class.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(results).flatten()\n",
    "print(predictions[:5])\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n",
    "                         \"Label\": predictions})\n",
    "submissions.to_csv(\"my_submissions.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1: 97%\n",
    "Architecture description:\n",
    "\n",
    "1. Batch Size: 64\n",
    "2. Learning rate: 0.001\n",
    "3. Number of parameters: 109386\n",
    "4. Dropout: 0.2\n",
    "5. Optimizer: Adam\n",
    "6. Input layer: 784\n",
    "7. Output layer: 10\n",
    "8. Number of epochs: 8\n",
    "\n",
    "Model 2: 97.6%\n",
    "Architecture description:\n",
    "\n",
    "1. Batch Size: 64\n",
    "2. Learning rate: 0.001\n",
    "3. Number of parameters: 109386\n",
    "4. Dropout: 0.2\n",
    "5. Optimizer: SGD(lr=1e-2,decay=1e-6, momentum=0.9, nesterov=True)\n",
    "6. Input layer: 784\n",
    "7. Output layer: 10\n",
    "8. Number of epochs: 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
